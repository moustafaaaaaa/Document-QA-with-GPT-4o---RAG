# ğŸ¤– Document Q&A with GPT-4o â€” Retrieval-Augmented Generation (RAG)

This project demonstrates how to build a **Document Question Answering (QA)** system using **GPT-4o** and **LangChain** with **Retrieval-Augmented Generation (RAG)** architecture.

It enables users to upload any **PDF document** ğŸ“„ and ask questions ğŸ’¬ about its content.  
The model retrieves the most relevant chunks from the document and generates accurate, context-aware answers using **GPT-4o**.

---

## ğŸš€ Key Features
âœ… Supports **PDF document ingestion**  
âœ… **Semantic text splitting** and embedding  
âœ… **FAISS** vector database for efficient similarity search  
âœ… Uses **HuggingFace Embeddings** for document representation  
âœ… Leverages **OpenAI GPT-4o** for high-quality natural language answers  
âœ… Simple, modular, and extendable design  

---

## ğŸ§  Project Overview

This RAG pipeline integrates **retrieval** and **generation**:

1. **Document Loading** â€” The document is loaded using `UnstructuredFileLoader` (handles PDF, text, and other formats).
2. **Chunking** â€” The text is split into manageable chunks with overlap to preserve context.
3. **Embedding** â€” Each chunk is embedded using `HuggingFaceEmbeddings` and stored in **FAISS**.
4. **Retrieval** â€” Given a user query, the most similar document chunks are retrieved.
5. **Generation** â€” The retrieverâ€™s results are passed to `GPT-4o` (via LangChainâ€™s `ChatOpenAI`), which formulates the final answer.

---

## ğŸ§© Tech Stack

| Component | Description |
|------------|--------------|
| ğŸ§  **GPT-4o** | Large Language Model from OpenAI for text generation |
| ğŸ§¾ **LangChain** | Framework for managing LLM pipelines and retrieval chains |
| ğŸ’¬ **LangChain-Community / OpenAI / HuggingFace** | Modular integrations for embeddings and LLMs |
| ğŸ” **FAISS** | Vector similarity search engine |
| ğŸ§© **Unstructured** | Document loader for parsing text & PDFs |
| ğŸ§  **HuggingFace Embeddings** | Generates dense vector representations of document text |

---

## âš™ï¸ Project Structure

document-qa-rag/
â”‚
â”œâ”€â”€ Document_QA_with_GPT4o_RAG.ipynb # Main Jupyter Notebook
â”œâ”€â”€ attention_is_all_you_need.pdf # Example document
â”œâ”€â”€ requirements.txt # Dependencies list
â””â”€â”€ README.md # Project documentation

makefile

---

## ğŸ§ª Example Workflow

```python
# Load and split document
loader = UnstructuredFileLoader("attention_is_all_you_need.pdf")
documents = loader.load()

# Split into chunks
text_splitter = CharacterTextSplitter(separator='/n', chunk_size=1000, chunk_overlap=200)
text_chunks = text_splitter.split_documents(documents)

# Embed and store in FAISS
embeddings = HuggingFaceEmbeddings()
knowledge_base = FAISS.from_documents(text_chunks, embeddings)

# Build retrieval + generation chain
qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(model="gpt-4o", temperature=0),
    retriever=knowledge_base.as_retriever()
)

# Ask questions
response = qa_chain.invoke({"query": "What is this document about?"})
print(response["result"])
```
ğŸ§° Installation & Setup
1ï¸âƒ£ Clone the repository

git clone https://github.com/<moustafaaaaaa>/document-qa-rag.git
cd document-qa-rag
2ï¸âƒ£ Install dependencies

pip install -r requirements.txt
or manually:
pip install transformers sentence-transformers langchain langchain-community langchain-openai faiss-cpu unstructured unstructured[pdf]
3ï¸âƒ£ Set your OpenAI API key
Before running, export your API key:

Windows (PowerShell):


setx OPENAI_API_KEY "your_openai_api_key"
macOS / Linux:

export OPENAI_API_KEY="your_openai_api_key"
4ï¸âƒ£ Run the notebook
Open and run:
jupyter notebook "Document QA with GPT-4o - RAG.ipynb"
